{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True  # Set to True if you want to use GPU\n",
    "device = torch.device('cuda' if USE_CUDA and torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuNLaZnuwFxB"
   },
   "outputs": [],
   "source": [
    "class Uber(Dataset):\n",
    "    def __init__(self, dir, seq_len=60):\n",
    "        self.seq_len = seq_len\n",
    "        # Skip first 3 rows (headers) and select specific columns\n",
    "        # usecols: High, Low, Open, Close, Volume\n",
    "        data = np.loadtxt(dir, delimiter=',', skiprows=3, usecols=(3,4,5,2,6), dtype=float)\n",
    "        self.X = self.normalize(data)\n",
    "        self.y = data[:, [0]]  # Using High price as target\n",
    "        self.len = len(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.len - self.seq_len)-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
    "        label = self.y[idx+self.seq_len+1]\n",
    "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def normalize(self, X):\n",
    "        X = np.transpose(X)\n",
    "        X_norm = []\n",
    "        for x in X:\n",
    "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
    "            X_norm.append(x)\n",
    "        return np.transpose(X_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJ26KwwvaHnr"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class IstanbulStock(Dataset):\n",
    "    def __init__(self, dir, seq_len=40):\n",
    "        self.seq_len = seq_len\n",
    "        data = np.loadtxt(dir, delimiter=',', skiprows=1, dtype=None)\n",
    "        self.X = self.normalize(data[:, [0,1,2,3,4,5,6,7]])\n",
    "        self.y = data[:, [0]]\n",
    "        self.num_labels = len(np.unique(self.y))\n",
    "        self.len = len(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.len - self.seq_len)-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
    "        label = self.y[idx+self.seq_len+1]\n",
    "\n",
    "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def normalize(self, X):\n",
    "        X = np.transpose(X)\n",
    "        X_norm = []\n",
    "        for x in X:\n",
    "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
    "            X_norm.append(x)\n",
    "        return np.transpose(X_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdsfkmm8F4Ri"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class AirQuality(Dataset):\n",
    "    def __init__(self, dir, seq_len=24):\n",
    "        self.seq_len = seq_len\n",
    "        data = np.loadtxt(dir, delimiter=',', skiprows=1, dtype=None)\n",
    "        self.X = self.normalize(data[:, [0,1,2,3,4,5,6,7,8,9,10,11]])\n",
    "        self.y = data[:, [4]]\n",
    "        self.num_labels = len(np.unique(self.y))\n",
    "        self.len = len(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.len - self.seq_len)-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
    "        label = self.y[idx+self.seq_len+1]\n",
    "\n",
    "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def normalize(self, X):\n",
    "        X = np.transpose(X)\n",
    "        X_norm = []\n",
    "        for x in X:\n",
    "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
    "            X_norm.append(x)\n",
    "        return np.transpose(X_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmzqDct4x2Nd"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class Traffic(Dataset):\n",
    "    def __init__(self, dir, seq_len=24):\n",
    "        self.seq_len = seq_len\n",
    "        data = np.loadtxt(dir, delimiter=',', skiprows=1, dtype=None)\n",
    "        self.X = self.normalize(data[:, [0,1,2,3,4,5,6,7]])\n",
    "        self.y = data[:, [7]]\n",
    "        self.num_labels = len(np.unique(self.y))\n",
    "        self.len = len(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.len - self.seq_len)-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
    "        label = self.y[idx+self.seq_len+1]\n",
    "\n",
    "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def normalize(self, X):\n",
    "        X = np.transpose(X)\n",
    "        X_norm = []\n",
    "        for x in X:\n",
    "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
    "            X_norm.append(x)\n",
    "        return np.transpose(X_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brWb5KsPzn42"
   },
   "outputs": [],
   "source": [
    "class AppliancesEnergy1(Dataset):\n",
    "    def __init__(self, dir, seq_len=144):\n",
    "        self.seq_len = seq_len\n",
    "        data = np.loadtxt(dir, delimiter=',', skiprows=1, dtype=None)\n",
    "        self.X = self.normalize(data[:, 0:26])\n",
    "        self.y = data[:, [0]]\n",
    "        self.num_labels = len(np.unique(self.y))\n",
    "        self.len = len(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.len - self.seq_len)-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
    "        label = self.y[idx+self.seq_len+1]\n",
    "\n",
    "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def normalize(self, X):\n",
    "        X = np.transpose(X)\n",
    "        X_norm = []\n",
    "        for x in X:\n",
    "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
    "            X_norm.append(x)\n",
    "        return np.transpose(X_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMiQJitnVlSN"
   },
   "outputs": [],
   "source": [
    "class AppliancesEnergy2(Dataset):\n",
    "    def __init__(self, dir, seq_len=144):\n",
    "        self.seq_len = seq_len\n",
    "        data = np.loadtxt(dir, delimiter=',', skiprows=1, dtype=None)\n",
    "        self.X = self.normalize(data[:, 0:26])\n",
    "        self.y = data[:, [1]]\n",
    "        self.num_labels = len(np.unique(self.y))\n",
    "        self.len = len(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.len - self.seq_len)-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
    "        label = self.y[idx+self.seq_len+1]\n",
    "\n",
    "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def normalize(self, X):\n",
    "        X = np.transpose(X)\n",
    "        X_norm = []\n",
    "        for x in X:\n",
    "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
    "            X_norm.append(x)\n",
    "        return np.transpose(X_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFhUi5YX2PGG"
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads, seq_len, module, rel_emb):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.device = device\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.seq_len = seq_len\n",
    "        self.module = module\n",
    "        self.rel_emb = rel_emb\n",
    "        modules = ['spatial', 'temporal', 'spatiotemporal', 'output']\n",
    "        assert (modules.__contains__(module)), \"Invalid module\"\n",
    "\n",
    "\n",
    "        if module == 'spatial' or module == 'temporal':\n",
    "            self.head_dim = seq_len\n",
    "            self.values = nn.Linear(self.embed_size, self.embed_size, dtype=torch.float32)\n",
    "            self.keys = nn.Linear(self.embed_size, self.embed_size, dtype=torch.float32, device=self.device)\n",
    "            self.queries = nn.Linear(self.embed_size, self.embed_size, dtype=torch.float32, device=self.device)\n",
    "\n",
    "            if rel_emb:\n",
    "                self.E = nn.Parameter(torch.randn([self.heads, self.head_dim, self.embed_size], device=self.device))\n",
    "\n",
    "\n",
    "        else:\n",
    "            self.head_dim = embed_size // heads\n",
    "            assert (self.head_dim * heads == embed_size), \"Embed size not div by heads\"\n",
    "            self.values = nn.Linear(self.head_dim, self.head_dim, dtype=torch.float32)\n",
    "            self.keys = nn.Linear(self.head_dim, self.head_dim, dtype=torch.float32, device=self.device)\n",
    "            self.queries = nn.Linear(self.head_dim, self.head_dim, dtype=torch.float32, device=self.device)\n",
    "\n",
    "            if rel_emb:\n",
    "                self.E = nn.Parameter(torch.randn([1, self.seq_len, self.head_dim], device=self.device))\n",
    "\n",
    "        self.fc_out = nn.Linear(self.embed_size, self.embed_size, device=self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, _, _ = x.shape\n",
    "\n",
    "        #non-shared weights between heads for spatial and temporal modules\n",
    "        if self.module == 'spatial' or self.module == 'temporal':\n",
    "            values = self.values(x)\n",
    "            keys = self.keys(x)\n",
    "            queries = self.queries(x)\n",
    "            values = values.reshape(N, self.seq_len, self.heads, self.embed_size)\n",
    "            keys = keys.reshape(N, self.seq_len, self.heads, self.embed_size)\n",
    "            queries = queries.reshape(N, self.seq_len, self.heads, self.embed_size)\n",
    "\n",
    "        #shared weights between heads for spatio-temporal module\n",
    "        else:\n",
    "            values, keys, queries = x, x, x\n",
    "            values = values.reshape(N, self.seq_len, self.heads, self.head_dim)\n",
    "            keys = keys.reshape(N, self.seq_len, self.heads, self.head_dim)\n",
    "            queries = queries.reshape(N, self.seq_len, self.heads, self.head_dim)\n",
    "            values = self.values(values)\n",
    "            keys = self.keys(keys)\n",
    "            queries = self.queries(queries)\n",
    "\n",
    "\n",
    "        if self.rel_emb:\n",
    "            QE = torch.matmul(queries.transpose(1, 2), self.E.transpose(1,2))\n",
    "            QE = self._mask_positions(QE)\n",
    "            S = self._skew(QE).contiguous().view(N, self.heads, self.seq_len, self.seq_len)\n",
    "            qk = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "            mask = torch.triu(torch.ones(1, self.seq_len, self.seq_len, device=self.device),\n",
    "                    1)\n",
    "            if mask is not None:\n",
    "                qk = qk.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "            attention = torch.softmax(qk / (self.embed_size ** (1/2)), dim=3) + S\n",
    "\n",
    "        else:\n",
    "            qk = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "            mask = torch.triu(torch.ones(1, self.seq_len, self.seq_len, device=self.device),\n",
    "                    1)\n",
    "            if mask is not None:\n",
    "                qk = qk.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "            attention = torch.softmax(qk / (self.embed_size ** (1/2)), dim=3)\n",
    "\n",
    "        #attention(N x Heads x Q_Len x K_len)\n",
    "        #values(N x V_len x Heads x Head_dim)\n",
    "        #z(N x Q_len x Heads*Head_dim)\n",
    "\n",
    "        if self.module == 'spatial' or self.module == 'temporal':\n",
    "            z = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, self.seq_len*self.heads, self.embed_size)\n",
    "        else:\n",
    "            z = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, self.seq_len, self.heads*self.head_dim)\n",
    "\n",
    "        z = self.fc_out(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "    def _mask_positions(self, qe):\n",
    "        L = qe.shape[-1]\n",
    "        mask = torch.triu(torch.ones(L, L, device=self.device), 1).flip(1)\n",
    "        return qe.masked_fill((mask == 1), 0)\n",
    "\n",
    "    def _skew(self, qe):\n",
    "        #pad a column of zeros on the left\n",
    "        padded_qe = F.pad(qe, [1,0])\n",
    "        s = padded_qe.shape\n",
    "        padded_qe = padded_qe.view(s[0], s[1], s[3], s[2])\n",
    "        #take out first (padded) row\n",
    "        return padded_qe[:,:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5x_4EVK2Rao"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, seq_len, module, forward_expansion, rel_emb):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads, seq_len, module, rel_emb=rel_emb)\n",
    "\n",
    "        if module == 'spatial' or module == 'temporal':\n",
    "            self.norm1 = nn.BatchNorm1d(seq_len*heads)\n",
    "            self.norm2 = nn.BatchNorm1d(seq_len*heads)\n",
    "        else:\n",
    "            self.norm1 = nn.BatchNorm1d(seq_len)\n",
    "            self.norm2 = nn.BatchNorm1d(seq_len)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.attention(x)\n",
    "        x = self.norm1(attention + x)\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.norm2(forward + x)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RfZxk9vr2URd"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, seq_len, embed_size, num_layers, heads, device,\n",
    "                 forward_expansion, module, output_size=1,\n",
    "                 rel_emb=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.module = module\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.rel_emb = rel_emb\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "             TransformerBlock(embed_size, heads, seq_len, module, forward_expansion=forward_expansion, rel_emb = rel_emb)\n",
    "             for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            out = layer(x)\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LWAXNXk2ZJj"
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_shape, output_size,\n",
    "                 embed_size, num_layers, forward_expansion, heads):\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "        self.batch_size, self.num_var, self.seq_len = input_shape\n",
    "        self.device = device\n",
    "        self.num_elements = self.seq_len*self.num_var\n",
    "        self.embed_size = embed_size\n",
    "        self.element_embedding = nn.Linear(self.seq_len, embed_size*self.seq_len)\n",
    "        self.pos_embedding = nn.Embedding(self.seq_len, embed_size)\n",
    "        self.variable_embedding = nn.Embedding(self.num_var, embed_size)\n",
    "\n",
    "\n",
    "        self.temporal = Encoder(seq_len=self.seq_len,\n",
    "                                embed_size=embed_size,\n",
    "                                num_layers=num_layers,\n",
    "                                heads=self.num_var,\n",
    "                                device=self.device,\n",
    "                                forward_expansion=forward_expansion,\n",
    "                                module='temporal',\n",
    "                                rel_emb=True)\n",
    "\n",
    "        self.spatial = Encoder(seq_len=self.num_var,\n",
    "                               embed_size=embed_size,\n",
    "                               num_layers=num_layers,\n",
    "                               heads=self.seq_len,\n",
    "                               device=self.device,\n",
    "                               forward_expansion=forward_expansion,\n",
    "                               module = 'spatial',\n",
    "                               rel_emb=True)\n",
    "\n",
    "        self.spatiotemporal = Encoder(seq_len=self.seq_len*self.num_var,\n",
    "                                      embed_size=embed_size,\n",
    "                                      num_layers=num_layers,\n",
    "                                      heads=heads,\n",
    "                                      device=self.device,\n",
    "                                      forward_expansion=forward_expansion,\n",
    "                                      module = 'spatiotemporal',\n",
    "                                      rel_emb=True)\n",
    "\n",
    "\n",
    "        # consolidate embedding dimension\n",
    "        self.fc_out1 = nn.Linear(embed_size, embed_size//2)\n",
    "        self.fc_out2 = nn.Linear(embed_size//2, 1)\n",
    "\n",
    "        #prediction\n",
    "        self.out = nn.Linear((self.num_elements*3), output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, dropout):\n",
    "        batch_size = len(x)\n",
    "\n",
    "        #process/embed input for temporal module\n",
    "        positions = torch.arange(0, self.seq_len).expand(batch_size, self.num_var, self.seq_len).reshape(batch_size, self.num_var * self.seq_len).to(self.device)\n",
    "        x_temporal = self.element_embedding(x).reshape(batch_size, self.num_elements, self.embed_size)\n",
    "        x_temporal = F.dropout(self.pos_embedding(positions) + x_temporal, dropout)\n",
    "\n",
    "        #process/embed input for spatial module\n",
    "        x_spatial = torch.transpose(x, 1, 2).reshape(batch_size, self.num_var, self.seq_len)\n",
    "        vars = torch.arange(0, self.num_var).expand(batch_size, self.seq_len, self.num_var).reshape(batch_size, self.num_var * self.seq_len).to(self.device)\n",
    "        x_spatial = self.element_embedding(x_spatial).reshape(batch_size, self.num_elements, self.embed_size)\n",
    "        x_spatial = F.dropout(self.variable_embedding(vars) + x_spatial, dropout)\n",
    "\n",
    "\n",
    "        #process/embed input for spatio-temporal module\n",
    "        positions = torch.arange(0, self.seq_len).expand(batch_size, self.num_var, self.seq_len).reshape(batch_size, self.num_var* self.seq_len).to(self.device)\n",
    "        x_spatio_temporal = self.element_embedding(x).reshape(batch_size, self.seq_len* self.num_var, self.embed_size)\n",
    "        x_spatio_temporal = F.dropout(self.pos_embedding(positions) + x_spatio_temporal, dropout)\n",
    "\n",
    "\n",
    "\n",
    "        out1 = self.temporal(x_temporal)\n",
    "        out2 = self.spatial(x_spatial)\n",
    "        out3 = self.spatiotemporal(x_spatio_temporal)\n",
    "        out = torch.cat((out1, out2, out3), 1)\n",
    "        out = self.fc_out1(out)\n",
    "        out = F.leaky_relu(out)\n",
    "        out = self.fc_out2(out)\n",
    "        out = F.leaky_relu(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.out(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uo9izz8mr2ev"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchmetrics import MeanSquaredError, MeanAbsolutePercentageError, MeanAbsoluteError\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# NUM_EPOCHS = 50\n",
    "# TEST_SPLIT = 0.5\n",
    "\n",
    "def plot_metrics(train_metrics, val_metrics, metric_names):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    clear_output(wait=True)\n",
    "    fig, axes = plt.subplots(1, len(metric_names), figsize=(15, 5))\n",
    "    \n",
    "    for i, metric_name in enumerate(metric_names):\n",
    "        axes[i].plot(train_metrics[metric_name], label=f'Train {metric_name}')\n",
    "        axes[i].plot(val_metrics[metric_name], label=f'Val {metric_name}')\n",
    "        axes[i].set_title(metric_name)\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def train_test(embed_size, heads, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset, NUM_EPOCHS, TEST_SPLIT):\n",
    "\n",
    "    datasets = ['Uber', 'Traffic', 'AirQuality', 'AppliancesEnergy1', 'AppliancesEnergy2', 'IstanbulStock']\n",
    "    assert (datasets.__contains__(dataset)), \"Invalid dataset\"\n",
    "\n",
    "    #call dataset class\n",
    "    if dataset == 'Uber':\n",
    "        train_data = Uber(dir)\n",
    "    elif dataset == 'Traffic':\n",
    "        train_data = Traffic(dir)\n",
    "    elif dataset == 'AirQuality':\n",
    "        train_data = AirQuality(dir)\n",
    "    elif dataset == 'AppliancesEnergy1':\n",
    "        train_data = AppliancesEnergy1(dir)\n",
    "    elif dataset == 'AppliancesEnergy2':\n",
    "        train_data = AppliancesEnergy2(dir)\n",
    "    elif dataset == 'IstanbulStock':\n",
    "        train_data = IstanbulStock(dir)\n",
    "\n",
    "\n",
    "\n",
    "    #split into train and test\n",
    "    dataset_size = len(train_data)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(TEST_SPLIT * dataset_size))\n",
    "    train_indices, test_indices = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                            sampler=train_sampler)\n",
    "    test_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                                    sampler=test_sampler)\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize metrics\n",
    "    train_mse = MeanSquaredError().to(device)\n",
    "    train_mae = MeanAbsoluteError().to(device)\n",
    "    train_mape = MeanAbsolutePercentageError().to(device)\n",
    "    \n",
    "    val_mse = MeanSquaredError().to(device)\n",
    "    val_mae = MeanAbsoluteError().to(device)\n",
    "    val_mape = MeanAbsolutePercentageError().to(device)\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    inputs, _ = next(iter(train_dataloader))\n",
    "    model = Transformer(inputs.shape, 1, embed_size=embed_size, num_layers=num_layers,\n",
    "                       forward_expansion=forward_expansion, heads=heads).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    # Metric history\n",
    "    history = {\n",
    "        'train': {'MSE': [], 'MAE': [], 'MAPE': []},\n",
    "        'val': {'MSE': [], 'MAE': [], 'MAPE': []}\n",
    "    }\n",
    "\n",
    "    # Early stopping setup\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, dropout)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update metrics\n",
    "            train_mse.update(outputs, labels)\n",
    "            train_mae.update(outputs, labels)\n",
    "            train_mape.update(outputs, labels)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs, 0)\n",
    "                \n",
    "                # Update metrics\n",
    "                val_mse.update(outputs, labels)\n",
    "                val_mae.update(outputs, labels)\n",
    "                val_mape.update(outputs, labels)\n",
    "\n",
    "        # Compute epoch metrics\n",
    "        epoch_train_mse = train_mse.compute()\n",
    "        epoch_train_mae = train_mae.compute()\n",
    "        epoch_train_mape = train_mape.compute()\n",
    "        \n",
    "        epoch_val_mse = val_mse.compute()\n",
    "        epoch_val_mae = val_mae.compute()\n",
    "        epoch_val_mape = val_mape.compute()\n",
    "\n",
    "        # Store metrics\n",
    "        history['train']['MSE'].append(epoch_train_mse.item())\n",
    "        history['train']['MAE'].append(epoch_train_mae.item())\n",
    "        history['train']['MAPE'].append(epoch_train_mape.item())\n",
    "        \n",
    "        history['val']['MSE'].append(epoch_val_mse.item())\n",
    "        history['val']['MAE'].append(epoch_val_mae.item())\n",
    "        history['val']['MAPE'].append(epoch_val_mape.item())\n",
    "\n",
    "        # Reset metrics for next epoch\n",
    "        train_mse.reset()\n",
    "        train_mae.reset()\n",
    "        train_mape.reset()\n",
    "        val_mse.reset()\n",
    "        val_mae.reset()\n",
    "        val_mape.reset()\n",
    "\n",
    "        # Early stopping check\n",
    "        if epoch_val_mse < best_val_loss:\n",
    "            best_val_loss = epoch_val_mse\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), f'best_model_{dataset}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Plot metrics every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            plot_metrics(\n",
    "                history['train'],\n",
    "                history['val'],\n",
    "                ['MSE', 'MAE', 'MAPE']\n",
    "            )\n",
    "            print(f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
    "            print(f'Train MSE: {epoch_train_mse:.4f}, MAE: {epoch_train_mae:.4f}, MAPE: {epoch_train_mape:.4f}')\n",
    "            print(f'Val MSE: {epoch_val_mse:.4f}, MAE: {epoch_val_mae:.4f}, MAPE: {epoch_val_mape:.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "            break\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Uber database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Download Uber stock data\n",
    "uber = yf.download('UBER', \n",
    "                   start='2019-05-10',  # Uber's IPO date\n",
    "                   end='2024-01-01',    # Current date\n",
    "                   progress=False)\n",
    "\n",
    "dir = 'DATA/uber_stock.csv'\n",
    "uber.to_csv(dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yriwM9-WURMG"
   },
   "source": [
    "Test Uber Stock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x92oTplm2abW"
   },
   "outputs": [],
   "source": [
    "# Model Architecture Parameters\n",
    "d = 32                    # Embedding dimension. Larger → More capacity to learn complex patterns [32 - 256]\n",
    "h = 4                     # Number of attention heads\n",
    "num_layers = 3           # Number of transformer layers. More layers → Deeper network, can learn more complex patterns [2 - 6]\n",
    "forward_expansion = 1    # Expansion factor for feedforward network. Larger → More capacity but more parameters [1 - 5]\n",
    "\n",
    "# Training Parameters\n",
    "dropout = 0.1           # Dropout rate for regularization. Higher → More regularization, less overfitting [0.1 - 0.5]\n",
    "lr = 0.001            # Learning rate. Higher → Faster learning but might be unstable [0.0001, 0.001]\n",
    "batch_size = 256       # Batch size. Larger → More stable gradients, more memory usage [32 - 512]\n",
    "NUM_EPOCHS = 50        # Number of epochs. Higher → More training, potentially better performance [50 - 100]\n",
    "TEST_SPLIT = 0.3       # Train/test split ratio. Higher → More validation data, less training data [0.2 - 0.3]\n",
    "\n",
    "dir = 'DATA/uber_stock.csv'  # Update this line to point to your file\n",
    "dataset = 'Uber'\n",
    "\n",
    "history =train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset, NUM_EPOCHS, TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFI5auziUVdS"
   },
   "source": [
    "Test Appliances Energy 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsdvYYqnUZke"
   },
   "outputs": [],
   "source": [
    "d = 8\n",
    "h = 4\n",
    "num_layers = 3\n",
    "forward_expansion = 1\n",
    "dropout = 0.1\n",
    "lr = 0.0001\n",
    "batch_size = 32\n",
    "dir = ''\n",
    "dataset = 'AppliancesEnergy1'\n",
    "train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wD9dlY9BUhV-"
   },
   "source": [
    "Test Appliances Energy 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2swGhmNlUcZy"
   },
   "outputs": [],
   "source": [
    "d = 8\n",
    "h = 4\n",
    "num_layers = 3\n",
    "forward_expansion = 1\n",
    "dropout = 0.1\n",
    "lr = 0.0001\n",
    "batch_size = 32\n",
    "dir = ''\n",
    "dataset = 'AppliancesEnergy2'\n",
    "\n",
    "train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uf14C1vDUjJE"
   },
   "source": [
    "Test BeijingPM2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbO8o-HkUteK"
   },
   "outputs": [],
   "source": [
    "d = 32\n",
    "h = 4\n",
    "num_layers = 3\n",
    "forward_expansion = 1\n",
    "dropout = 0.1\n",
    "lr = 0.0001\n",
    "batch_size = 256\n",
    "dir = ''\n",
    "dataset = 'AirQuality'\n",
    "\n",
    "train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYtjnNFzUt-X"
   },
   "source": [
    "Test Istanbul Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9e0TqtWU0qu"
   },
   "outputs": [],
   "source": [
    "d = 32\n",
    "h = 4\n",
    "num_layers = 3\n",
    "forward_expansion = 1\n",
    "dropout = 0.1\n",
    "lr = 0.00005\n",
    "batch_size = 268\n",
    "dir = ''\n",
    "dataset = 'IstanbulStock'\n",
    "\n",
    "train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OgEMPR2U1K_"
   },
   "source": [
    "Test Metro Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMMEqxMlU5fg"
   },
   "outputs": [],
   "source": [
    "d = 32\n",
    "h = 4\n",
    "num_layers = 3\n",
    "forward_expansion = 1\n",
    "dropout = 0.1\n",
    "lr = 0.0001\n",
    "batch_size = 256\n",
    "dir = ''\n",
    "dataset = 'Traffic'\n",
    "\n",
    "train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
